{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 591 300 987\n"
     ]
    }
   ],
   "source": [
    "import keras, sys, cv2, os\n",
    "from keras.models import Model, load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import atan2, degrees\n",
    "\n",
    "img_size = 224\n",
    "base_path = 'samples'\n",
    "file_list = sorted(os.listdir(base_path))\n",
    "\n",
    "# 고양이 얼굴에 씌워질 안경  \n",
    "glasses = cv2.imread('images/glasses.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# bbs_model_name = sys.argv[1]\n",
    "# print(bbs_model_name)\n",
    "\n",
    "# lmks_model_name = sys.argv[2]\n",
    "# print(lmks_model_name)\n",
    "\n",
    "#bbs_model = load_model(bbs_model_name)\n",
    "#lmks_model = load_model(lmks_model_name)\n",
    "\n",
    "# 모델을 로드한다.\n",
    "bbs_model = load_model('models/bbs_1.h5')\n",
    "lmks_model = load_model('models/lmks_1.h5')\n",
    "\n",
    "# 모델링할 때와 같이 이미지를 정사각형의 모양으로 만드는 함수\n",
    "def resize_img(im):\n",
    "  old_size = im.shape[:2] # old_size is in (height, width) format\n",
    "  ratio = float(img_size) / max(old_size)\n",
    "  new_size = tuple([int(x*ratio) for x in old_size])\n",
    "  # new_size should be in (width, height) format\n",
    "  im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "  delta_w = img_size - new_size[1]\n",
    "  delta_h = img_size - new_size[0]\n",
    "  top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "  left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "  new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
    "      value=[0, 0, 0])\n",
    "  return new_im, ratio, top, left\n",
    "\n",
    "# overlay function\n",
    "# 이미지 덧씌우기\n",
    "def overlay_transparent(background_img, img_to_overlay_t, x, y, overlay_size=None):\n",
    "  bg_img = background_img.copy()\n",
    "  # convert 3 channels to 4 channels\n",
    "  if bg_img.shape[2] == 3:\n",
    "    bg_img = cv2.cvtColor(bg_img, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "  if overlay_size is not None:\n",
    "    img_to_overlay_t = cv2.resize(img_to_overlay_t.copy(), overlay_size)\n",
    "\n",
    "  b, g, r, a = cv2.split(img_to_overlay_t)\n",
    "\n",
    "  mask = cv2.medianBlur(a, 5)\n",
    "\n",
    "  h, w, _ = img_to_overlay_t.shape\n",
    "  roi = bg_img[int(y-h/2):int(y+h/2), int(x-w/2):int(x+w/2)]\n",
    "\n",
    "  img1_bg = cv2.bitwise_and(roi.copy(), roi.copy(), mask=cv2.bitwise_not(mask))\n",
    "  img2_fg = cv2.bitwise_and(img_to_overlay_t, img_to_overlay_t, mask=mask)\n",
    "\n",
    "  bg_img[int(y-h/2):int(y+h/2), int(x-w/2):int(x+w/2)] = cv2.add(img1_bg, img2_fg)\n",
    "\n",
    "  # convert 4 channels to 4 channels\n",
    "  bg_img = cv2.cvtColor(bg_img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "  return bg_img\n",
    "\n",
    "# 기울기함수\n",
    "def angle_between(p1, p2):\n",
    "  xDiff = p2[0] - p1[0]\n",
    "  yDiff = p2[1] - p1[1]\n",
    "  return degrees(atan2(yDiff, xDiff))\n",
    "\n",
    "# testing\n",
    "for f in file_list:\n",
    "  if '.jpg' not in f:\n",
    "    continue\n",
    "\n",
    "  img = cv2.imread(os.path.join(base_path, f))\n",
    "  ori_img = img.copy()\n",
    "  result_img = img.copy()\n",
    "\n",
    "  # predict bounding box\n",
    "  img, ratio, top, left = resize_img(img)\n",
    "\n",
    "  inputs = (img.astype('float32') / 255).reshape((1, img_size, img_size, 3))\n",
    "  pred_bb = bbs_model.predict(inputs)[0].reshape((-1, 2))\n",
    "\n",
    "  # compute bounding box of original image\n",
    "  # 원본 바운드 박스 좌표 찾기 \n",
    "  ori_bb = ((pred_bb - np.array([left, top])) / ratio).astype(np.int)\n",
    "  # compute lazy bounding box for detecting landmarks\n",
    "  # 바운드 박스 영역 그대로 하면 너무 작아서 인식을 잘못하기 때문에 바운드박스의 사이즈를 늘려준다. \n",
    "  center = np.mean(ori_bb, axis=0) # 왼쪽 상단과 오른쪽 하단의 중간 좌표 즉 바운드박스의 가운데를 의미\n",
    "  face_size = max(np.abs(ori_bb[1] - ori_bb[0]))\n",
    "  new_bb = np.array([\n",
    "    center - face_size * 0.6,\n",
    "    center + face_size * 0.6\n",
    "  ]).astype(np.int)\n",
    "  new_bb = np.clip(new_bb, 0, 99999) # 바운드 박스 배열이 0보다 작으면 0으로 처리 \n",
    "\n",
    "  # predict landmarks\n",
    "  face_img = ori_img[new_bb[0][1]:new_bb[1][1], new_bb[0][0]:new_bb[1][0]]\n",
    "  face_img, face_ratio, face_top, face_left = resize_img(face_img)\n",
    "\n",
    "  face_inputs = (face_img.astype('float32') / 255).reshape((1, img_size, img_size, 3))\n",
    "\n",
    "  pred_lmks = lmks_model.predict(face_inputs)[0].reshape((-1, 2))\n",
    "\n",
    "  # compute landmark of original image\n",
    "  # 원래의 형태로 변형 \n",
    "  new_lmks = ((pred_lmks - np.array([face_left, face_top])) / face_ratio).astype(np.int)\n",
    "  ori_lmks = new_lmks + new_bb[0]\n",
    "\n",
    "  # visualize\n",
    "  # 바운드 박스와 이목구비 좌표 그리기 \n",
    "  cv2.rectangle(ori_img, pt1=tuple(ori_bb[0]), pt2=tuple(ori_bb[1]), color=(255, 255, 255), thickness=2)\n",
    "\n",
    "  for i, l in enumerate(ori_lmks):\n",
    "    cv2.putText(ori_img, str(i), tuple(l), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    cv2.circle(ori_img, center=tuple(l), radius=1, color=(255, 255, 255), thickness=2)\n",
    "\n",
    "  # wearing glasses\n",
    "  glasses_center = np.mean([ori_lmks[0], ori_lmks[1]], axis=0) # 0 번과 1번이 왼쪽눈 오른쪽눈 그래서 가운데 점을 찾는다.\n",
    "  glasses_size = np.linalg.norm(ori_lmks[0] - ori_lmks[1]) * 2 # 안경사이즈는 왼쪽 오른쪽눈 길이의 2배 \n",
    "  \n",
    "  angle = -angle_between(ori_lmks[0], ori_lmks[1])\n",
    "  M = cv2.getRotationMatrix2D((glasses.shape[1] / 2, glasses.shape[0] / 2), angle, 1)\n",
    "  rotated_glasses = cv2.warpAffine(glasses, M, (glasses.shape[1],glasses.shape[0]))\n",
    "\n",
    "  try:\n",
    "    result_img = overlay_transparent(result_img, rotated_glasses, glasses_center[0], glasses_center[1], overlay_size=(int(glasses_size), int(glasses.shape[0] * glasses_size / glasses.shape[1])))\n",
    "  except:\n",
    "    print('failed overlay image')\n",
    "    \n",
    "  cv2.imshow('img', ori_img)\n",
    "  cv2.imshow('result', result_img)\n",
    "  filename, ext = os.path.splitext(f)\n",
    "  cv2.imwrite('result/%s_lmks%s' % (filename, ext), ori_img)\n",
    "  cv2.imwrite('result/%s_result%s' % (filename, ext), result_img)\n",
    "\n",
    "  if cv2.waitKey(0) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
